# LeanVibe Deployment Guide

Comprehensive guide to deploying and operating LeanVibe's autonomous deployment system. This guide covers everything from local development deployment to production operations with 99.9% uptime targets.

## üöÄ Deployment Overview

### Autonomous Deployment Philosophy
- **85%+ autonomous deployments** without human intervention
- **Canary deployments** with automatic promotion or rollback
- **Synthetic health monitoring** with intelligent failure detection
- **Zero-downtime deployments** with blue-green switching
- **Instant rollback** capability (<30 seconds)

### Architecture Components
```mermaid
graph TB
    subgraph "Development"
        DEV[Developer] --> PR[Pull Request]
        PR --> CI[CI Pipeline]
    end
    
    subgraph "Staging Environment" 
        CI --> STAGE_DEPLOY[Canary Deploy]
        STAGE_DEPLOY --> STAGE_PROBES[Synthetic Probes]
        STAGE_PROBES --> STAGE_DECISION{Healthy?}
    end
    
    subgraph "Production Environment"
        STAGE_DECISION -->|Yes| PROD_DEPLOY[Production Deploy]
        STAGE_DECISION -->|No| ROLLBACK[Auto Rollback]
        PROD_DEPLOY --> PROD_PROBES[Production Monitoring]
        PROD_PROBES --> PROD_DECISION{Healthy?}
        PROD_DECISION -->|No| PROD_ROLLBACK[Emergency Rollback]
    end
```

## üèóÔ∏è Environment Setup

### Local Development Deployment

#### Prerequisites
```bash
# Install Docker and Docker Compose
curl -fsSL https://get.docker.com -o get-docker.sh
sudo sh get-docker.sh

# Install Docker Compose
sudo curl -L "https://github.com/docker/compose/releases/latest/download/docker-compose-$(uname -s)-$(uname -m)" -o /usr/local/bin/docker-compose
sudo chmod +x /usr/local/bin/docker-compose
```

#### Local Environment Startup
```bash
# Clone repository
git clone https://github.com/your-org/leanvibe-ai.git
cd leanvibe-ai

# Start local development stack
docker-compose up -d

# Verify services are running
docker-compose ps

# Check service health
curl http://localhost:8000/health
curl http://localhost:8001/health  # CLI service
```

#### Local Configuration
```yaml
# docker-compose.yml (development)
version: '3.8'

services:
  backend:
    build: 
      context: ./leanvibe-backend
      target: development
    ports:
      - "8000:8000"
    environment:
      - ENVIRONMENT=development
      - DATABASE_URL=postgresql://dev:dev@postgres:5432/leanvibe_dev
      - REDIS_URL=redis://redis:6379/0
    volumes:
      - ./leanvibe-backend:/app
    depends_on:
      - postgres
      - redis
    
  cli:
    build: ./leanvibe-cli
    ports:
      - "8001:8001"
    environment:
      - BACKEND_URL=http://backend:8000
    depends_on:
      - backend
      
  postgres:
    image: postgres:15-alpine
    environment:
      POSTGRES_DB: leanvibe_dev
      POSTGRES_USER: dev
      POSTGRES_PASSWORD: dev
    ports:
      - "5432:5432"
    volumes:
      - postgres_dev_data:/var/lib/postgresql/data
      
  redis:
    image: redis:7-alpine
    ports:
      - "6379:6379"
    volumes:
      - redis_dev_data:/data

volumes:
  postgres_dev_data:
  redis_dev_data:
```

### Staging Environment

#### Infrastructure Setup (AWS/Cloud)
```bash
# Create staging environment
terraform -chdir=infrastructure/staging plan
terraform -chdir=infrastructure/staging apply

# Configure environment variables
aws ssm put-parameter \
  --name "/leanvibe/staging/database-url" \
  --value "postgresql://user:pass@staging-db.amazonaws.com:5432/leanvibe" \
  --type "SecureString"

aws ssm put-parameter \
  --name "/leanvibe/staging/api-key" \
  --value "staging-api-key-secure" \
  --type "SecureString"
```

#### Staging Configuration
```yaml
# docker-compose.staging.yml
version: '3.8'

services:
  backend:
    build: 
      context: ./leanvibe-backend
      target: production
    ports:
      - "8000:8000"
    environment:
      - ENVIRONMENT=staging
      - DATABASE_URL=${DATABASE_URL}
      - REDIS_URL=${REDIS_URL}
      - API_KEY=${API_KEY}
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
    restart: unless-stopped
    
  nginx:
    image: nginx:alpine
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ./config/nginx-staging.conf:/etc/nginx/nginx.conf
      - /etc/letsencrypt:/etc/letsencrypt
    depends_on:
      - backend
    restart: unless-stopped

  synthetic-probes:
    build: ./monitoring
    environment:
      - TARGET_URL=https://staging.leanvibe.ai
      - PROBE_INTERVAL=60
      - ALERT_WEBHOOK=${SLACK_WEBHOOK_URL}
    depends_on:
      - backend
    restart: unless-stopped
```

### Production Environment

#### High Availability Setup
```yaml
# docker-compose.production.yml
version: '3.8'

services:
  backend:
    image: leanvibe/backend:${VERSION}
    deploy:
      replicas: 3
      update_config:
        parallelism: 1
        delay: 30s
        order: start-first
        failure_action: rollback
      rollback_config:
        parallelism: 1
        delay: 30s
      restart_policy:
        condition: on-failure
        delay: 5s
        max_attempts: 3
        window: 60s
    environment:
      - ENVIRONMENT=production
      - DATABASE_URL=${DATABASE_URL}
      - REDIS_URL=${REDIS_URL}
      - SECRET_KEY=${SECRET_KEY}
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 15s
      timeout: 5s
      retries: 3
      start_period: 60s
    networks:
      - app-network
    
  loadbalancer:
    image: nginx:alpine
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ./config/nginx-production.conf:/etc/nginx/nginx.conf
      - /etc/ssl/certs:/etc/ssl/certs
    deploy:
      replicas: 2
      placement:
        constraints:
          - node.role == manager
    networks:
      - app-network
    depends_on:
      - backend

  monitoring:
    image: leanvibe/monitoring:latest
    environment:
      - TARGETS=https://api.leanvibe.ai
      - ALERT_CHANNELS=${ALERT_CHANNELS}
      - PROBE_FREQUENCY=30s
    deploy:
      replicas: 2
    networks:
      - app-network

networks:
  app-network:
    external: true
```

## üîÑ Autonomous CI/CD Pipeline

### GitHub Actions Workflow

#### Main Pipeline (.github/workflows/autonomous.yml)
```yaml
name: Autonomous Deployment Pipeline

on:
  push:
    branches: [main]
  pull_request:
    branches: [main]

concurrency:
  group: ${{ github.workflow }}-${{ github.ref }}
  cancel-in-progress: true

jobs:
  # Tier 0: Pre-commit validation (<60s)
  tier-0-validation:
    runs-on: ubuntu-latest
    timeout-minutes: 2
    outputs:
      should-deploy: ${{ steps.check.outputs.should-deploy }}
    steps:
      - uses: actions/checkout@v4
      
      - name: Setup Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'
          cache: 'pip'
      
      - name: Install dependencies
        run: |
          cd leanvibe-backend
          pip install -e .[dev,test]
      
      - name: Run Tier 0 tests
        run: |
          cd leanvibe-backend
          make test-tier0
      
      - name: Check deployment readiness
        id: check
        run: |
          if [[ "${{ github.event_name }}" == "push" && "${{ github.ref }}" == "refs/heads/main" ]]; then
            echo "should-deploy=true" >> $GITHUB_OUTPUT
          else
            echo "should-deploy=false" >> $GITHUB_OUTPUT
          fi

  # Tier 1: PR Gate validation (3-5m)
  tier-1-validation:
    runs-on: ubuntu-latest
    timeout-minutes: 5
    if: github.event_name == 'pull_request' || needs.tier-0-validation.outputs.should-deploy == 'true'
    needs: tier-0-validation
    steps:
      - uses: actions/checkout@v4
      
      - name: Setup Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'
          cache: 'pip'
      
      - name: Setup services
        run: |
          docker-compose -f docker-compose.test.yml up -d postgres redis
          sleep 10
      
      - name: Run Tier 1 tests
        run: |
          cd leanvibe-backend
          make test-tier1
      
      - name: Quality ratchet enforcement
        run: |
          cd leanvibe-backend
          python tools/quality_ratchet.py --enforce
      
      - name: Coverage report
        uses: codecov/codecov-action@v3
        with:
          file: ./leanvibe-backend/test_results/coverage.xml

  # Build and push container images
  build-images:
    runs-on: ubuntu-latest
    needs: [tier-0-validation, tier-1-validation]
    if: needs.tier-0-validation.outputs.should-deploy == 'true'
    outputs:
      backend-image: ${{ steps.meta.outputs.tags }}
      backend-digest: ${{ steps.build.outputs.digest }}
    steps:
      - uses: actions/checkout@v4
      
      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3
      
      - name: Login to Container Registry
        uses: docker/login-action@v3
        with:
          registry: ghcr.io
          username: ${{ github.actor }}
          password: ${{ secrets.GITHUB_TOKEN }}
      
      - name: Extract metadata
        id: meta
        uses: docker/metadata-action@v5
        with:
          images: ghcr.io/${{ github.repository }}/backend
          tags: |
            type=ref,event=branch
            type=sha,prefix={{branch}}-
            type=raw,value=latest,enable={{is_default_branch}}
      
      - name: Build and push
        id: build
        uses: docker/build-push-action@v5
        with:
          context: ./leanvibe-backend
          push: true
          tags: ${{ steps.meta.outputs.tags }}
          labels: ${{ steps.meta.outputs.labels }}
          cache-from: type=gha
          cache-to: type=gha,mode=max
          platforms: linux/amd64,linux/arm64

  # Canary deployment to staging
  canary-deployment:
    runs-on: ubuntu-latest
    needs: [build-images]
    environment: staging
    outputs:
      deployment-url: ${{ steps.deploy.outputs.url }}
      health-status: ${{ steps.health.outputs.status }}
    steps:
      - uses: actions/checkout@v4
      
      - name: Deploy to staging (canary)
        id: deploy
        run: |
          ./deploy/canary.sh staging ${{ needs.build-images.outputs.backend-image }}
          echo "url=https://staging.leanvibe.ai" >> $GITHUB_OUTPUT
      
      - name: Wait for deployment stabilization
        run: sleep 60
      
      - name: Run synthetic health probes
        id: health
        run: |
          ./deploy/synthetic_probes.sh staging --comprehensive
          echo "status=healthy" >> $GITHUB_OUTPUT
      
      - name: Rollback on failure
        if: failure()
        run: |
          ./deploy/rollback.sh staging --emergency
          exit 1

  # Auto-merge PR (if all checks pass)
  auto-merge-pr:
    runs-on: ubuntu-latest
    needs: [canary-deployment]
    if: github.event_name == 'pull_request' && contains(github.event.pull_request.labels.*.name, 'auto-merge')
    steps:
      - name: Auto-merge PR
        uses: pascalgn/merge-action@v0.15.6
        with:
          github_token: ${{ secrets.GITHUB_TOKEN }}
          merge_method: squash

  # Production deployment
  production-deployment:
    runs-on: ubuntu-latest
    needs: [canary-deployment]
    if: github.ref == 'refs/heads/main' && needs.canary-deployment.outputs.health-status == 'healthy'
    environment: production
    steps:
      - uses: actions/checkout@v4
      
      - name: Deploy to production
        run: |
          ./deploy/production.sh ${{ needs.build-images.outputs.backend-image }}
      
      - name: Run production health checks
        run: |
          sleep 120  # Allow time for deployment
          ./deploy/synthetic_probes.sh production --critical-path-only
      
      - name: Update deployment status
        run: |
          echo "‚úÖ Production deployment successful" >> $GITHUB_STEP_SUMMARY
          echo "üîó Health check: https://api.leanvibe.ai/health" >> $GITHUB_STEP_SUMMARY
          echo "üìä Monitoring: https://monitoring.leanvibe.ai" >> $GITHUB_STEP_SUMMARY
      
      - name: Notify deployment success
        uses: 8398a7/action-slack@v3
        with:
          status: success
          text: "üöÄ LeanVibe production deployment successful"
        env:
          SLACK_WEBHOOK_URL: ${{ secrets.SLACK_WEBHOOK_URL }}

  # Emergency rollback on production failure
  emergency-rollback:
    runs-on: ubuntu-latest
    needs: [production-deployment]
    if: failure()
    environment: production
    steps:
      - uses: actions/checkout@v4
      
      - name: Emergency rollback
        run: |
          ./deploy/rollback.sh production --emergency
      
      - name: Notify rollback
        uses: 8398a7/action-slack@v3
        with:
          status: failure
          text: "üö® Emergency rollback executed for LeanVibe production"
        env:
          SLACK_WEBHOOK_URL: ${{ secrets.SLACK_WEBHOOK_URL }}
```

### Deployment Scripts

#### Canary Deployment Script
```bash
#!/bin/bash
# deploy/canary.sh - Canary deployment with health monitoring

set -euo pipefail

ENVIRONMENT=${1:-staging}
IMAGE_TAG=${2:-latest}
SCRIPT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"

# Colors for output
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
NC='\033[0m' # No Color

log_info() {
    echo -e "${BLUE}[INFO]${NC} $1"
}

log_success() {
    echo -e "${GREEN}[SUCCESS]${NC} $1"
}

log_warning() {
    echo -e "${YELLOW}[WARNING]${NC} $1"
}

log_error() {
    echo -e "${RED}[ERROR]${NC} $1"
}

# Configuration
if [[ "$ENVIRONMENT" == "staging" ]]; then
    COMPOSE_FILE="docker-compose.staging.yml"
    BASE_URL="https://staging.leanvibe.ai"
elif [[ "$ENVIRONMENT" == "production" ]]; then
    COMPOSE_FILE="docker-compose.production.yml"
    BASE_URL="https://api.leanvibe.ai"
else
    log_error "Unknown environment: $ENVIRONMENT"
    exit 1
fi

log_info "Starting canary deployment to $ENVIRONMENT"
log_info "Image: $IMAGE_TAG"
log_info "Base URL: $BASE_URL"

# Pre-deployment health check
log_info "Running pre-deployment health check..."
if curl -f "$BASE_URL/health" > /dev/null 2>&1; then
    log_success "Pre-deployment health check passed"
else
    log_warning "Pre-deployment health check failed (may be expected for first deployment)"
fi

# Export environment variables for docker-compose
export VERSION="$IMAGE_TAG"
export DATABASE_URL="${DATABASE_URL:-}"
export REDIS_URL="${REDIS_URL:-}"
export API_KEY="${API_KEY:-}"

# Start canary deployment (10% traffic initially)
log_info "Deploying canary (10% traffic)..."
docker-compose -f "$COMPOSE_FILE" up -d --no-deps backend

# Wait for service to start
log_info "Waiting for service to start..."
sleep 30

# Health check with retries
log_info "Running health checks..."
for i in {1..12}; do  # 12 attempts = 2 minutes
    if curl -f "$BASE_URL/health" > /dev/null 2>&1; then
        log_success "Health check passed (attempt $i)"
        break
    else
        if [[ $i -eq 12 ]]; then
            log_error "Health check failed after 2 minutes"
            exit 1
        fi
        log_info "Health check failed, retrying in 10 seconds... (attempt $i/12)"
        sleep 10
    fi
done

# Run comprehensive health probes
log_info "Running comprehensive health probes..."
if "$SCRIPT_DIR/synthetic_probes.sh" "$ENVIRONMENT" --comprehensive; then
    log_success "Synthetic probes passed"
else
    log_error "Synthetic probes failed"
    exit 1
fi

# Gradual traffic increase (if production)
if [[ "$ENVIRONMENT" == "production" ]]; then
    log_info "Gradually increasing traffic to canary..."
    
    # 25% traffic
    log_info "Increasing to 25% traffic..."
    # Update load balancer configuration here
    sleep 60
    
    if ! "$SCRIPT_DIR/synthetic_probes.sh" "$ENVIRONMENT" --quick; then
        log_error "Health probes failed at 25% traffic"
        exit 1
    fi
    
    # 50% traffic
    log_info "Increasing to 50% traffic..."
    # Update load balancer configuration here
    sleep 60
    
    if ! "$SCRIPT_DIR/synthetic_probes.sh" "$ENVIRONMENT" --quick; then
        log_error "Health probes failed at 50% traffic"
        exit 1
    fi
    
    # 100% traffic
    log_info "Switching to 100% traffic..."
    # Update load balancer configuration here
    sleep 30
fi

# Final health verification
log_info "Running final health verification..."
if "$SCRIPT_DIR/synthetic_probes.sh" "$ENVIRONMENT" --comprehensive; then
    log_success "Canary deployment successful!"
    echo "‚úÖ Deployment URL: $BASE_URL"
    echo "üìä Health status: $BASE_URL/health"
else
    log_error "Final health verification failed"
    exit 1
fi

log_success "Canary deployment completed successfully"
```

#### Rollback Script
```bash
#!/bin/bash
# deploy/rollback.sh - Emergency rollback functionality

set -euo pipefail

ENVIRONMENT=${1:-staging}
TARGET_VERSION=${2:-previous}
SCRIPT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"

log_info() {
    echo -e "\033[0;34m[INFO]\033[0m $1"
}

log_error() {
    echo -e "\033[0;31m[ERROR]\033[0m $1"
}

log_success() {
    echo -e "\033[0;32m[SUCCESS]\033[0m $1"
}

# Emergency mode flag
EMERGENCY_MODE=false
if [[ "${3:-}" == "--emergency" ]]; then
    EMERGENCY_MODE=true
    log_info "üö® EMERGENCY ROLLBACK MODE ACTIVATED"
fi

# Configuration
if [[ "$ENVIRONMENT" == "staging" ]]; then
    COMPOSE_FILE="docker-compose.staging.yml"
    BASE_URL="https://staging.leanvibe.ai"
elif [[ "$ENVIRONMENT" == "production" ]]; then
    COMPOSE_FILE="docker-compose.production.yml"
    BASE_URL="https://api.leanvibe.ai"
else
    log_error "Unknown environment: $ENVIRONMENT"
    exit 1
fi

log_info "Starting rollback for $ENVIRONMENT environment"

# Get previous version if not specified
if [[ "$TARGET_VERSION" == "previous" ]]; then
    # Get the last known good version from deployment history
    if [[ -f "deployment_history.json" ]]; then
        TARGET_VERSION=$(jq -r '.[-2].version // "latest"' deployment_history.json)
    else
        TARGET_VERSION="latest"
        log_info "No deployment history found, rolling back to latest stable"
    fi
fi

log_info "Rolling back to version: $TARGET_VERSION"

# Record rollback start time for metrics
ROLLBACK_START=$(date +%s)

# Emergency rollback - skip health checks and roll back immediately
if [[ "$EMERGENCY_MODE" == "true" ]]; then
    log_info "üö® Performing emergency rollback (skipping safety checks)"
    
    # Stop current deployment
    docker-compose -f "$COMPOSE_FILE" down --remove-orphans
    
    # Start previous version
    export VERSION="$TARGET_VERSION"
    docker-compose -f "$COMPOSE_FILE" up -d
    
    # Quick health check (don't fail rollback if this fails)
    sleep 15
    if curl -f "$BASE_URL/health" > /dev/null 2>&1; then
        log_success "Emergency rollback completed - service is responding"
    else
        log_error "Service not responding after emergency rollback - manual intervention required"
    fi
    
else
    # Normal rollback with safety checks
    
    # Pre-rollback verification
    log_info "Verifying rollback target is valid..."
    if ! docker manifest inspect "leanvibe/backend:$TARGET_VERSION" > /dev/null 2>&1; then
        log_error "Target version $TARGET_VERSION not found in registry"
        exit 1
    fi
    
    # Graceful rollback
    log_info "Performing graceful rollback..."
    
    # Update configuration to target version
    export VERSION="$TARGET_VERSION"
    
    # Blue-green rollback strategy
    log_info "Starting rollback deployment..."
    docker-compose -f "$COMPOSE_FILE" up -d --no-deps backend
    
    # Wait for service to stabilize
    log_info "Waiting for service to stabilize..."
    sleep 45
    
    # Health verification
    log_info "Verifying rollback health..."
    for i in {1..6}; do  # 1 minute of attempts
        if curl -f "$BASE_URL/health" > /dev/null 2>&1; then
            log_success "Rollback health check passed (attempt $i)"
            break
        else
            if [[ $i -eq 6 ]]; then
                log_error "Rollback health check failed - service may be degraded"
                # Continue anyway since we're rolling back
            fi
            log_info "Health check failed, retrying... (attempt $i/6)"
            sleep 10
        fi
    done
    
    # Run basic synthetic probes
    log_info "Running post-rollback validation..."
    if "$SCRIPT_DIR/synthetic_probes.sh" "$ENVIRONMENT" --quick; then
        log_success "Post-rollback validation passed"
    else
        log_error "Post-rollback validation failed - manual investigation required"
    fi
fi

# Calculate rollback time
ROLLBACK_END=$(date +%s)
ROLLBACK_DURATION=$((ROLLBACK_END - ROLLBACK_START))

# Update deployment history
if [[ -f "deployment_history.json" ]]; then
    jq --arg version "$TARGET_VERSION" --arg timestamp "$(date -Iseconds)" --arg duration "$ROLLBACK_DURATION" --arg type "rollback" '
        . += [{
            version: $version,
            timestamp: $timestamp,
            duration: ($duration | tonumber),
            type: $type,
            environment: "'$ENVIRONMENT'"
        }]
    ' deployment_history.json > deployment_history.tmp && mv deployment_history.tmp deployment_history.json
fi

# Notification
if [[ "$EMERGENCY_MODE" == "true" ]]; then
    log_success "üö® Emergency rollback completed in ${ROLLBACK_DURATION}s"
    echo "‚ö†Ô∏è  Manual verification recommended"
else
    log_success "‚úÖ Rollback completed successfully in ${ROLLBACK_DURATION}s"
    echo "üîó Service URL: $BASE_URL"
    echo "üìä Health check: $BASE_URL/health"
fi

echo "üìù Rolled back to version: $TARGET_VERSION"
echo "‚è±Ô∏è  Rollback duration: ${ROLLBACK_DURATION} seconds"

# Alert if rollback took too long
if [[ $ROLLBACK_DURATION -gt 60 ]]; then
    log_error "‚ö†Ô∏è  Rollback took longer than expected (${ROLLBACK_DURATION}s > 60s)"
fi

log_success "Rollback operation completed"
```

#### Synthetic Probes Script
```bash
#!/bin/bash
# deploy/synthetic_probes.sh - Comprehensive health monitoring

set -euo pipefail

ENVIRONMENT=${1:-staging}
MODE=${2:---comprehensive}
SCRIPT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"

# Configuration based on environment
if [[ "$ENVIRONMENT" == "staging" ]]; then
    BASE_URL="https://staging.leanvibe.ai"
    API_KEY="${STAGING_API_KEY:-test-api-key}"
elif [[ "$ENVIRONMENT" == "production" ]]; then
    BASE_URL="https://api.leanvibe.ai"
    API_KEY="${PROD_API_KEY:-}"
else
    echo "‚ùå Unknown environment: $ENVIRONMENT"
    exit 1
fi

# Probe configuration
TIMEOUT=10
SUCCESS_THRESHOLD=0.85  # 85% success rate required
PROBE_RESULTS=()

log_probe() {
    echo "üîç $1"
}

log_success() {
    echo "‚úÖ $1"
}

log_failure() {
    echo "‚ùå $1"
}

log_warning() {
    echo "‚ö†Ô∏è  $1"
}

# Individual probe functions
probe_basic_health() {
    log_probe "Testing basic health endpoint..."
    
    local start_time=$(date +%s.%3N)
    local response_code
    
    if response_code=$(curl -s -o /dev/null -w "%{http_code}" --max-time "$TIMEOUT" "$BASE_URL/health"); then
        local end_time=$(date +%s.%3N)
        local duration=$(echo "$end_time - $start_time" | bc)
        local duration_ms=$(echo "$duration * 1000" | bc)
        
        if [[ "$response_code" == "200" ]]; then
            log_success "Basic health check passed (${duration_ms}ms)"
            return 0
        else
            log_failure "Basic health check failed with status $response_code"
            return 1
        fi
    else
        log_failure "Basic health check failed - connection error"
        return 1
    fi
}

probe_database_health() {
    log_probe "Testing database connectivity..."
    
    local response_code
    if response_code=$(curl -s -o /dev/null -w "%{http_code}" --max-time "$TIMEOUT" "$BASE_URL/health/database"); then
        if [[ "$response_code" == "200" ]]; then
            log_success "Database health check passed"
            return 0
        else
            log_failure "Database health check failed with status $response_code"
            return 1
        fi
    else
        log_failure "Database health check failed - connection error"
        return 1
    fi
}

probe_api_functionality() {
    log_probe "Testing API functionality..."
    
    # Test task creation and retrieval
    local task_response
    if task_response=$(curl -s -X POST "$BASE_URL/api/v1/tasks" \
        -H "Content-Type: application/json" \
        -H "Authorization: Bearer $API_KEY" \
        -d '{"title":"Probe Test Task","description":"Synthetic monitoring test"}' \
        --max-time "$TIMEOUT"); then
        
        local task_id
        if task_id=$(echo "$task_response" | jq -r '.id // empty'); then
            if [[ -n "$task_id" ]]; then
                # Test task retrieval
                local get_response_code
                if get_response_code=$(curl -s -o /dev/null -w "%{http_code}" \
                    -H "Authorization: Bearer $API_KEY" \
                    --max-time "$TIMEOUT" \
                    "$BASE_URL/api/v1/tasks/$task_id"); then
                    
                    if [[ "$get_response_code" == "200" ]]; then
                        # Cleanup - delete test task
                        curl -s -X DELETE "$BASE_URL/api/v1/tasks/$task_id" \
                            -H "Authorization: Bearer $API_KEY" \
                            --max-time "$TIMEOUT" > /dev/null
                        
                        log_success "API functionality test passed"
                        return 0
                    fi
                fi
            fi
        fi
    fi
    
    log_failure "API functionality test failed"
    return 1
}

probe_websocket_connectivity() {
    log_probe "Testing WebSocket connectivity..."
    
    # Use Python script for WebSocket testing
    if python3 -c "
import asyncio
import websockets
import json
import sys
from datetime import datetime

async def test_websocket():
    try:
        uri = '$BASE_URL'.replace('http', 'ws') + '/ws'
        async with websockets.connect(uri, timeout=$TIMEOUT) as websocket:
            # Send ping message
            ping_msg = {'type': 'ping', 'timestamp': datetime.now().isoformat()}
            await websocket.send(json.dumps(ping_msg))
            
            # Wait for response
            response = await asyncio.wait_for(websocket.recv(), timeout=5)
            data = json.loads(response)
            
            # Validate response
            if 'type' in data:
                return True
    except Exception as e:
        return False
    return False

result = asyncio.run(test_websocket())
sys.exit(0 if result else 1)
" 2>/dev/null; then
        log_success "WebSocket connectivity test passed"
        return 0
    else
        log_failure "WebSocket connectivity test failed"
        return 1
    fi
}

probe_performance_benchmarks() {
    log_probe "Testing performance benchmarks..."
    
    local total_time=0
    local request_count=5
    local failed_requests=0
    
    for i in $(seq 1 $request_count); do
        local start_time=$(date +%s.%3N)
        local response_code
        
        if response_code=$(curl -s -o /dev/null -w "%{http_code}" --max-time "$TIMEOUT" "$BASE_URL/health"); then
            local end_time=$(date +%s.%3N)
            local duration=$(echo "$end_time - $start_time" | bc)
            total_time=$(echo "$total_time + $duration" | bc)
            
            if [[ "$response_code" != "200" ]]; then
                ((failed_requests++))
            fi
        else
            ((failed_requests++))
        fi
    done
    
    if [[ $failed_requests -eq 0 ]]; then
        local avg_time=$(echo "scale=3; $total_time / $request_count * 1000" | bc)
        local avg_time_int=${avg_time%.*}  # Convert to integer for comparison
        
        if [[ ${avg_time_int:-0} -lt 1000 ]]; then  # Less than 1 second average
            log_success "Performance benchmark passed (avg: ${avg_time}ms)"
            return 0
        else
            log_warning "Performance benchmark slow (avg: ${avg_time}ms)"
            return 1
        fi
    else
        log_failure "Performance benchmark failed ($failed_requests/$request_count requests failed)"
        return 1
    fi
}

probe_security_headers() {
    log_probe "Testing security headers..."
    
    local headers
    if headers=$(curl -s -I --max-time "$TIMEOUT" "$BASE_URL/health"); then
        local security_score=0
        local max_score=4
        
        # Check for security headers
        if echo "$headers" | grep -qi "strict-transport-security"; then
            ((security_score++))
        fi
        
        if echo "$headers" | grep -qi "x-content-type-options"; then
            ((security_score++))
        fi
        
        if echo "$headers" | grep -qi "x-frame-options"; then
            ((security_score++))
        fi
        
        if echo "$headers" | grep -qi "x-xss-protection"; then
            ((security_score++))
        fi
        
        if [[ $security_score -ge 3 ]]; then  # At least 3/4 security headers
            log_success "Security headers check passed ($security_score/$max_score)"
            return 0
        else
            log_warning "Security headers check failed ($security_score/$max_score)"
            return 1
        fi
    else
        log_failure "Security headers check failed - connection error"
        return 1
    fi
}

# Run probes based on mode
run_probes() {
    local probes=()
    local results=()
    
    case "$MODE" in
        "--quick")
            probes=(probe_basic_health probe_api_functionality)
            ;;
        "--comprehensive")
            probes=(probe_basic_health probe_database_health probe_api_functionality probe_websocket_connectivity probe_performance_benchmarks probe_security_headers)
            ;;
        "--critical-path-only")
            probes=(probe_basic_health probe_database_health probe_api_functionality)
            ;;
        *)
            probes=(probe_basic_health probe_database_health probe_api_functionality probe_websocket_connectivity)
            ;;
    esac
    
    echo "üöÄ Running ${#probes[@]} probes for $ENVIRONMENT environment ($MODE mode)"
    echo ""
    
    local passed=0
    local total=${#probes[@]}
    
    for probe in "${probes[@]}"; do
        if $probe; then
            ((passed++))
            results+=("‚úÖ")
        else
            results+=("‚ùå")
        fi
        echo ""
    done
    
    # Calculate success rate
    local success_rate=$(echo "scale=2; $passed / $total" | bc)
    local success_percentage=$(echo "$success_rate * 100" | bc)
    local success_percentage_int=${success_percentage%.*}
    
    echo "üìä Results Summary:"
    echo "   Passed: $passed/$total probes"
    echo "   Success rate: ${success_percentage_int}%"
    echo "   Required: $(echo "$SUCCESS_THRESHOLD * 100" | bc | cut -d. -f1)%"
    echo ""
    
    # Check if success rate meets threshold
    local threshold_int=$(echo "$SUCCESS_THRESHOLD * 100" | bc | cut -d. -f1)
    if [[ ${success_percentage_int:-0} -ge ${threshold_int:-85} ]]; then
        log_success "‚úÖ Synthetic probes PASSED (${success_percentage_int}% success rate)"
        return 0
    else
        log_failure "‚ùå Synthetic probes FAILED (${success_percentage_int}% success rate below ${threshold_int}%)"
        return 1
    fi
}

# Main execution
main() {
    echo "üîç LeanVibe Synthetic Health Probes"
    echo "Environment: $ENVIRONMENT"
    echo "Mode: $MODE"
    echo "Target URL: $BASE_URL"
    echo ""
    
    if ! command -v bc &> /dev/null; then
        echo "‚ùå bc calculator not found. Please install: apt-get install bc"
        exit 1
    fi
    
    if ! command -v jq &> /dev/null; then
        echo "‚ùå jq not found. Please install: apt-get install jq"
        exit 1
    fi
    
    if run_probes; then
        echo "üéâ All synthetic probes completed successfully!"
        exit 0
    else
        echo "üí• Synthetic probes failed - system may be unhealthy"
        exit 1
    fi
}

# Execute main function
main "$@"
```

## üìä Monitoring and Observability

### Health Check Endpoints
```python
# app/api/health.py
from fastapi import APIRouter, Depends, HTTPException
from sqlalchemy.ext.asyncio import AsyncSession
from app.core.database import get_database_session
from app.core.redis import get_redis_client
import aioredis
import asyncio
from datetime import datetime

router = APIRouter()

@router.get("/health")
async def basic_health():
    """Basic health check - fast response."""
    return {
        "status": "healthy",
        "timestamp": datetime.utcnow().isoformat(),
        "version": "1.0.0"
    }

@router.get("/health/complete")
async def complete_health(db: AsyncSession = Depends(get_database_session)):
    """Comprehensive health check with all dependencies."""
    health_status = {
        "status": "healthy",
        "timestamp": datetime.utcnow().isoformat(),
        "version": "1.0.0",
        "checks": {}
    }
    
    overall_healthy = True
    
    # Database connectivity check
    try:
        await db.execute("SELECT 1")
        health_status["checks"]["database"] = {
            "status": "healthy",
            "response_time_ms": 0  # Would measure actual response time
        }
    except Exception as e:
        health_status["checks"]["database"] = {
            "status": "unhealthy",
            "error": str(e)
        }
        overall_healthy = False
    
    # Redis connectivity check
    try:
        redis = await get_redis_client()
        await redis.ping()
        health_status["checks"]["redis"] = {
            "status": "healthy",
            "response_time_ms": 0
        }
    except Exception as e:
        health_status["checks"]["redis"] = {
            "status": "unhealthy", 
            "error": str(e)
        }
        overall_healthy = False
    
    # AI service health (if applicable)
    try:
        # Check AI service connectivity
        health_status["checks"]["ai_service"] = {
            "status": "healthy",
            "model_loaded": True
        }
    except Exception as e:
        health_status["checks"]["ai_service"] = {
            "status": "unhealthy",
            "error": str(e)
        }
        overall_healthy = False
    
    health_status["status"] = "healthy" if overall_healthy else "unhealthy"
    
    if not overall_healthy:
        raise HTTPException(status_code=503, detail=health_status)
    
    return health_status

@router.get("/health/database")
async def database_health(db: AsyncSession = Depends(get_database_session)):
    """Dedicated database health check."""
    try:
        start_time = asyncio.get_event_loop().time()
        await db.execute("SELECT COUNT(*) FROM tasks")
        response_time = (asyncio.get_event_loop().time() - start_time) * 1000
        
        return {
            "database_connected": True,
            "response_time_ms": round(response_time, 2),
            "status": "healthy"
        }
    except Exception as e:
        raise HTTPException(status_code=503, detail={
            "database_connected": False,
            "error": str(e),
            "status": "unhealthy"
        })
```

### Production Monitoring Dashboard
```python
# monitoring/dashboard.py
from flask import Flask, render_template, jsonify
import requests
import json
from datetime import datetime, timedelta
import sqlite3

app = Flask(__name__)

class HealthMonitor:
    def __init__(self, db_path="monitoring.db"):
        self.db_path = db_path
        self.init_database()
    
    def init_database(self):
        """Initialize monitoring database."""
        conn = sqlite3.connect(self.db_path)
        conn.execute("""
            CREATE TABLE IF NOT EXISTS health_checks (
                timestamp TEXT,
                environment TEXT,
                endpoint TEXT,
                status_code INTEGER,
                response_time_ms REAL,
                success BOOLEAN
            )
        """)
        conn.commit()
        conn.close()
    
    def record_health_check(self, environment, endpoint, status_code, response_time, success):
        """Record health check result."""
        conn = sqlite3.connect(self.db_path)
        conn.execute("""
            INSERT INTO health_checks 
            (timestamp, environment, endpoint, status_code, response_time_ms, success)
            VALUES (?, ?, ?, ?, ?, ?)
        """, (datetime.utcnow().isoformat(), environment, endpoint, status_code, response_time, success))
        conn.commit()
        conn.close()
    
    def get_recent_metrics(self, hours=24):
        """Get recent health metrics."""
        since = datetime.utcnow() - timedelta(hours=hours)
        conn = sqlite3.connect(self.db_path)
        cursor = conn.execute("""
            SELECT environment, endpoint, 
                   AVG(response_time_ms) as avg_response_time,
                   (COUNT(*) FILTER (WHERE success = 1) * 100.0 / COUNT(*)) as success_rate,
                   COUNT(*) as total_checks
            FROM health_checks 
            WHERE timestamp > ?
            GROUP BY environment, endpoint
            ORDER BY environment, endpoint
        """, (since.isoformat(),))
        
        results = []
        for row in cursor:
            results.append({
                "environment": row[0],
                "endpoint": row[1],
                "avg_response_time": round(row[2] or 0, 2),
                "success_rate": round(row[3] or 0, 2),
                "total_checks": row[4]
            })
        
        conn.close()
        return results

monitor = HealthMonitor()

@app.route("/")
def dashboard():
    """Main monitoring dashboard."""
    return render_template("dashboard.html")

@app.route("/api/metrics")
def get_metrics():
    """API endpoint for dashboard metrics."""
    metrics = monitor.get_recent_metrics()
    return jsonify(metrics)

@app.route("/api/run-probes")
def run_probes():
    """Trigger synthetic probes manually."""
    environments = ["staging", "production"]
    results = {}
    
    for env in environments:
        try:
            # Run synthetic probes
            result = subprocess.run([
                "./deploy/synthetic_probes.sh", env, "--comprehensive"
            ], capture_output=True, text=True)
            
            results[env] = {
                "success": result.returncode == 0,
                "output": result.stdout,
                "error": result.stderr
            }
        except Exception as e:
            results[env] = {
                "success": False,
                "error": str(e)
            }
    
    return jsonify(results)

if __name__ == "__main__":
    app.run(host="0.0.0.0", port=5000, debug=False)
```

## üîß Configuration Management

### Environment Configuration
```yaml
# config/environments.yml
development:
  database:
    url: postgresql://dev:dev@localhost:5432/leanvibe_dev
    pool_size: 5
    echo: true
  
  redis:
    url: redis://localhost:6379/0
    max_connections: 10
  
  api:
    debug: true
    cors_origins: ["http://localhost:3000"]
    rate_limit: "1000/minute"
  
  monitoring:
    enabled: false
    log_level: DEBUG

staging:
  database:
    url: ${DATABASE_URL}
    pool_size: 10
    echo: false
  
  redis:
    url: ${REDIS_URL}
    max_connections: 50
  
  api:
    debug: false
    cors_origins: ["https://staging.leanvibe.ai"]
    rate_limit: "100/minute"
  
  monitoring:
    enabled: true
    log_level: INFO
    synthetic_probes:
      interval: 60  # seconds
      timeout: 10

production:
  database:
    url: ${DATABASE_URL}
    pool_size: 20
    echo: false
    ssl_mode: require
  
  redis:
    url: ${REDIS_URL}
    max_connections: 100
    ssl: true
  
  api:
    debug: false
    cors_origins: ["https://leanvibe.ai"]
    rate_limit: "60/minute"
  
  monitoring:
    enabled: true
    log_level: WARNING
    synthetic_probes:
      interval: 30  # seconds
      timeout: 5
    alerts:
      slack_webhook: ${SLACK_WEBHOOK_URL}
      email_alerts: true
```

### Feature Flags Configuration
```yaml
# config/feature_flags.yml
features:
  new_ai_model:
    enabled: false
    environments: ["staging"]
    rollout_percentage: 0
    description: "New AI model with improved accuracy"
    
  websocket_v2:
    enabled: true
    environments: ["staging", "production"]
    rollout_percentage: 50
    description: "WebSocket protocol v2 with improved performance"
    
  enhanced_monitoring:
    enabled: true
    environments: ["production"]
    rollout_percentage: 100
    description: "Enhanced monitoring with detailed metrics"
```

## üö® Troubleshooting

### Common Deployment Issues

#### Deployment Failure Analysis
```bash
# Check deployment logs
docker-compose logs app --tail=100

# Verify service health
curl -f https://api.leanvibe.ai/health/complete

# Check container status
docker ps -a | grep leanvibe

# Inspect container logs
docker logs <container_id> --tail=100

# Check resource usage
docker stats
```

#### Rollback Scenarios
```bash
# Emergency rollback (immediate)
./deploy/rollback.sh production --emergency

# Rollback to specific version
./deploy/rollback.sh production v1.2.3

# Rollback staging environment
./deploy/rollback.sh staging

# Check rollback status
curl https://api.leanvibe.ai/health
```

#### Database Migration Issues
```bash
# Check migration status
cd leanvibe-backend
python -m alembic current

# Apply pending migrations
python -m alembic upgrade head

# Rollback migration
python -m alembic downgrade -1

# Reset to clean state (development only)
python -m alembic downgrade base
python -m alembic upgrade head
```

### Performance Issues

#### Application Performance
```bash
# Check response times
curl -w "@curl-format.txt" -s -o /dev/null https://api.leanvibe.ai/health

# Monitor resource usage
docker stats
htop

# Database performance
cd leanvibe-backend
python -c "
from app.core.database import engine
import asyncio
async def test():
    async with engine.connect() as conn:
        result = await conn.execute('SELECT pg_stat_activity();')
        print(list(result))
asyncio.run(test())
"
```

#### Load Testing
```bash
# Install siege load testing tool
sudo apt-get install siege

# Run load test
siege -c 10 -t 60s https://api.leanvibe.ai/health

# More comprehensive load test
ab -n 1000 -c 10 https://api.leanvibe.ai/api/v1/tasks
```

### Security Issues

#### Certificate Problems
```bash
# Check SSL certificate
openssl s_client -connect api.leanvibe.ai:443 -servername api.leanvibe.ai

# Renew Let's Encrypt certificate
certbot renew --nginx

# Test certificate renewal
certbot renew --dry-run
```

#### Security Scanning
```bash
# Run security scan
cd leanvibe-backend
bandit -r app/

# Check for vulnerabilities
safety check

# Docker security scan
docker scan leanvibe/backend:latest
```

## üìà Performance Optimization

### Application Optimization
- **Database Connection Pooling**: Configure optimal pool sizes per environment
- **Redis Caching**: Implement caching for frequently accessed data
- **Async Operations**: Use async/await for all I/O operations
- **Resource Limits**: Set appropriate memory and CPU limits
- **CDN Integration**: Use CDN for static assets

### Infrastructure Optimization
- **Load Balancing**: Distribute traffic across multiple instances
- **Auto Scaling**: Configure horizontal scaling based on metrics
- **Resource Monitoring**: Track CPU, memory, and disk usage
- **Network Optimization**: Optimize network latency and throughput

### Cost Optimization
- **Resource Right-Sizing**: Match resources to actual usage
- **Scheduled Scaling**: Scale down during low-traffic periods
- **Reserved Instances**: Use reserved capacity for predictable workloads
- **Cost Monitoring**: Track and optimize cloud costs

## üìö Additional Resources

- [Autonomous Deployment Guide](leanvibe-backend/AUTONOMOUS_DEPLOYMENT.md) - Detailed CI/CD pipeline
- [Development Guide](DEVELOPMENT_GUIDE.md) - Complete developer onboarding
- [Testing Guide](TESTING_GUIDE.md) - Comprehensive testing strategy
- [Contributing Guide](CONTRIBUTING.md) - How to contribute

---

**üöÄ This deployment guide enables 85%+ autonomous deployments while maintaining 99.9% uptime. The system is designed to handle most scenarios automatically, with human intervention only required for architectural changes or critical issues.**