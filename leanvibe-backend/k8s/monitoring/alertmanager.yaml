# LeanVibe Enterprise AlertManager Configuration
# Production-ready alerting and notification management
apiVersion: v1
kind: ConfigMap
metadata:
  name: alertmanager-config
  namespace: leanvibe-monitoring
  labels:
    app.kubernetes.io/name: alertmanager
    app.kubernetes.io/component: config
data:
  alertmanager.yml: |
    global:
      smtp_smarthost: 'smtp.leanvibe.ai:587'
      smtp_from: 'alerts@leanvibe.ai'
      smtp_auth_username: 'alerts@leanvibe.ai'
      smtp_auth_password: 'smtp-password'
      resolve_timeout: 5m
      
      slack_api_url: 'https://hooks.slack.com/services/YOUR/SLACK/WEBHOOK'
      
      pagerduty_url: 'https://events.pagerduty.com/v2/enqueue'
      
    templates:
    - '/etc/alertmanager/templates/*.tmpl'
    
    route:
      group_by: ['alertname', 'cluster', 'service']
      group_wait: 10s
      group_interval: 10s
      repeat_interval: 12h
      receiver: 'default-receiver'
      
      routes:
      # Critical alerts - immediate notification
      - match:
          severity: critical
        receiver: 'critical-alerts'
        group_wait: 10s
        group_interval: 30s
        repeat_interval: 5m
        continue: true
      
      # Business metric alerts
      - match:
          category: business
        receiver: 'business-alerts'
        group_wait: 5m
        group_interval: 30m
        repeat_interval: 2h
        continue: true
      
      # Database alerts
      - match:
          service: neo4j
        receiver: 'database-alerts'
        group_wait: 30s
        group_interval: 5m
        repeat_interval: 30m
      
      - match:
          service: redis
        receiver: 'cache-alerts'  
        group_wait: 30s
        group_interval: 5m
        repeat_interval: 30m
      
      # Infrastructure alerts
      - match:
          category: infrastructure
        receiver: 'infrastructure-alerts'
        group_wait: 2m
        group_interval: 10m
        repeat_interval: 1h
    
    inhibit_rules:
    # Inhibit any warning-level alerts when the same alert is already critical
    - source_match:
        severity: 'critical'
      target_match:
        severity: 'warning'
      equal: ['alertname', 'cluster', 'service']
    
    # Inhibit instance-level alerts when entire service is down
    - source_match:
        alertname: 'ServiceDown'
      target_match_re:
        alertname: '.*'
      equal: ['service']
    
    receivers:
    # Default receiver for non-critical alerts
    - name: 'default-receiver'
      email_configs:
      - to: 'alerts@leanvibe.ai'
        subject: '[{{ .Status | toUpper }}] {{ .GroupLabels.SortedPairs.Values | join " " }} ({{ .Alerts | len }} alerts)'
        body: |
          {{ range .Alerts }}
          Alert: {{ .Annotations.summary }}
          Description: {{ .Annotations.description }}
          Severity: {{ .Labels.severity }}
          Service: {{ .Labels.service }}
          Instance: {{ .Labels.instance }}
          {{ end }}
      
      slack_configs:
      - api_url: '{{ .slack_api_url }}'
        channel: '#alerts-general'
        title: '[{{ .Status | toUpper }}] {{ .GroupLabels.SortedPairs.Values | join " " }}'
        text: |
          {{ range .Alerts }}
          *Alert:* {{ .Annotations.summary }}
          *Description:* {{ .Annotations.description }}
          *Severity:* {{ .Labels.severity }}
          *Service:* {{ .Labels.service }}
          *Instance:* {{ .Labels.instance }}
          {{ end }}
    
    # Critical alerts - escalated notifications
    - name: 'critical-alerts'
      email_configs:
      - to: 'devops@leanvibe.ai,oncall@leanvibe.ai'
        subject: '[CRITICAL] {{ .GroupLabels.SortedPairs.Values | join " " }} - IMMEDIATE ACTION REQUIRED'
        body: |
          üö® CRITICAL ALERT - IMMEDIATE ACTION REQUIRED üö®
          
          {{ range .Alerts }}
          Alert: {{ .Annotations.summary }}
          Description: {{ .Annotations.description }}
          Severity: {{ .Labels.severity }}
          Service: {{ .Labels.service }}
          Instance: {{ .Labels.instance }}
          Started: {{ .StartsAt }}
          
          Runbook: https://docs.leanvibe.ai/runbooks/{{ .Labels.service }}
          Dashboard: https://grafana.leanvibe.ai/d/{{ .Labels.service }}
          {{ end }}
      
      slack_configs:
      - api_url: '{{ .slack_api_url }}'
        channel: '#alerts-critical'
        title: 'üö® [CRITICAL] {{ .GroupLabels.SortedPairs.Values | join " " }}'
        text: |
          <!channel> CRITICAL ALERT - IMMEDIATE ACTION REQUIRED
          {{ range .Alerts }}
          *Alert:* {{ .Annotations.summary }}
          *Description:* {{ .Annotations.description }}
          *Service:* {{ .Labels.service }}
          *Instance:* {{ .Labels.instance }}
          *Started:* {{ .StartsAt }}
          *Runbook:* https://docs.leanvibe.ai/runbooks/{{ .Labels.service }}
          *Dashboard:* https://grafana.leanvibe.ai/d/{{ .Labels.service }}
          {{ end }}
      
      pagerduty_configs:
      - routing_key: 'your-pagerduty-integration-key'
        description: '{{ .GroupLabels.SortedPairs.Values | join " " }}'
        details:
          summary: '{{ range .Alerts }}{{ .Annotations.summary }}{{ end }}'
          severity: 'critical'
          service: '{{ .GroupLabels.service }}'
    
    # Business alerts for revenue and customer impact
    - name: 'business-alerts'
      email_configs:
      - to: 'business@leanvibe.ai,devops@leanvibe.ai'
        subject: '[BUSINESS] {{ .GroupLabels.SortedPairs.Values | join " " }} - Revenue Impact'
        body: |
          üìä BUSINESS METRIC ALERT
          
          {{ range .Alerts }}
          Alert: {{ .Annotations.summary }}
          Description: {{ .Annotations.description }}
          Impact: Business revenue and customer satisfaction
          Started: {{ .StartsAt }}
          {{ end }}
      
      slack_configs:
      - api_url: '{{ .slack_api_url }}'
        channel: '#alerts-business'
        title: 'üìä [BUSINESS] {{ .GroupLabels.SortedPairs.Values | join " " }}'
        text: |
          Business metric alert detected - potential revenue impact
          {{ range .Alerts }}
          *Alert:* {{ .Annotations.summary }}
          *Description:* {{ .Annotations.description }}
          *Started:* {{ .StartsAt }}
          {{ end }}
    
    # Database-specific alerts
    - name: 'database-alerts'
      email_configs:
      - to: 'database-team@leanvibe.ai,devops@leanvibe.ai'
        subject: '[DATABASE] {{ .GroupLabels.SortedPairs.Values | join " " }} - Data Layer Alert'
        body: |
          üóÑÔ∏è DATABASE ALERT
          
          {{ range .Alerts }}
          Alert: {{ .Annotations.summary }}
          Description: {{ .Annotations.description }}
          Service: {{ .Labels.service }}
          Instance: {{ .Labels.instance }}
          
          Database Runbook: https://docs.leanvibe.ai/runbooks/database
          Database Dashboard: https://grafana.leanvibe.ai/d/database
          {{ end }}
      
      slack_configs:
      - api_url: '{{ .slack_api_url }}'
        channel: '#alerts-database'
        title: 'üóÑÔ∏è [DATABASE] {{ .GroupLabels.SortedPairs.Values | join " " }}'
        text: |
          Database alert detected
          {{ range .Alerts }}
          *Alert:* {{ .Annotations.summary }}
          *Service:* {{ .Labels.service }}
          *Instance:* {{ .Labels.instance }}
          {{ end }}
    
    # Cache-specific alerts
    - name: 'cache-alerts'
      email_configs:
      - to: 'devops@leanvibe.ai'
        subject: '[CACHE] {{ .GroupLabels.SortedPairs.Values | join " " }} - Cache Layer Alert'
        body: |
          ‚ö° CACHE ALERT
          
          {{ range .Alerts }}
          Alert: {{ .Annotations.summary }}
          Description: {{ .Annotations.description }}
          Service: {{ .Labels.service }}
          Instance: {{ .Labels.instance }}
          {{ end }}
    
    # Infrastructure alerts  
    - name: 'infrastructure-alerts'
      email_configs:
      - to: 'infrastructure@leanvibe.ai,devops@leanvibe.ai'
        subject: '[INFRA] {{ .GroupLabels.SortedPairs.Values | join " " }} - Infrastructure Alert'
        body: |
          üèóÔ∏è INFRASTRUCTURE ALERT
          
          {{ range .Alerts }}
          Alert: {{ .Annotations.summary }}
          Description: {{ .Annotations.description }}
          Category: {{ .Labels.category }}
          
          Infrastructure Runbook: https://docs.leanvibe.ai/runbooks/infrastructure
          Kubernetes Dashboard: https://grafana.leanvibe.ai/d/kubernetes
          {{ end }}
      
      slack_configs:
      - api_url: '{{ .slack_api_url }}'
        channel: '#alerts-infrastructure'
        title: 'üèóÔ∏è [INFRA] {{ .GroupLabels.SortedPairs.Values | join " " }}'
        text: |
          Infrastructure alert detected
          {{ range .Alerts }}
          *Alert:* {{ .Annotations.summary }}
          *Category:* {{ .Labels.category }}
          {{ end }}

  # Email templates
  email.tmpl: |
    {{ define "email.subject" }}
    [{{ .Status | toUpper }}] {{ .GroupLabels.SortedPairs.Values | join " " }}
    {{ end }}
    
    {{ define "email.html" }}
    <html>
    <head>
      <style>
        body { font-family: Arial, sans-serif; }
        .alert { border-left: 4px solid #ff6b6b; padding: 10px; margin: 10px 0; }
        .alert.resolved { border-left-color: #51cf66; }
        .severity-critical { background-color: #ffe0e0; }
        .severity-warning { background-color: #fff3cd; }
        .severity-info { background-color: #d1ecf1; }
      </style>
    </head>
    <body>
      <h2>{{ .GroupLabels.SortedPairs.Values | join " " }}</h2>
      <p><strong>Status:</strong> {{ .Status | toUpper }}</p>
      <p><strong>Group:</strong> {{ range .GroupLabels.SortedPairs }}{{ .Name }}={{ .Value }} {{ end }}</p>
      
      {{ range .Alerts }}
      <div class="alert {{ if eq .Status "resolved" }}resolved{{ end }} severity-{{ .Labels.severity }}">
        <h3>{{ .Annotations.summary }}</h3>
        <p><strong>Description:</strong> {{ .Annotations.description }}</p>
        <p><strong>Severity:</strong> {{ .Labels.severity }}</p>
        <p><strong>Service:</strong> {{ .Labels.service }}</p>
        <p><strong>Instance:</strong> {{ .Labels.instance }}</p>
        <p><strong>Started:</strong> {{ .StartsAt }}</p>
        {{ if .EndsAt }}<p><strong>Ended:</strong> {{ .EndsAt }}</p>{{ end }}
        
        {{ if .Labels.service }}
        <p>
          <a href="https://docs.leanvibe.ai/runbooks/{{ .Labels.service }}">üìñ Runbook</a> | 
          <a href="https://grafana.leanvibe.ai/d/{{ .Labels.service }}">üìä Dashboard</a>
        </p>
        {{ end }}
      </div>
      {{ end }}
      
      <hr>
      <p><small>
        This alert was generated by LeanVibe Enterprise Monitoring.<br>
        For support, contact <a href="mailto:devops@leanvibe.ai">devops@leanvibe.ai</a>
      </small></p>
    </body>
    </html>
    {{ end }}
---
# AlertManager Deployment
apiVersion: apps/v1
kind: Deployment
metadata:
  name: alertmanager
  namespace: leanvibe-monitoring
  labels:
    app.kubernetes.io/name: alertmanager
    app.kubernetes.io/instance: production
    app.kubernetes.io/component: alerting
spec:
  replicas: 2
  strategy:
    type: RollingUpdate
    rollingUpdate:
      maxUnavailable: 1
      maxSurge: 1
  selector:
    matchLabels:
      app.kubernetes.io/name: alertmanager
      app.kubernetes.io/component: alerting
  template:
    metadata:
      labels:
        app.kubernetes.io/name: alertmanager
        app.kubernetes.io/component: alerting
        app.kubernetes.io/version: "0.25.0"
      annotations:
        prometheus.io/scrape: "true"
        prometheus.io/port: "9093"
        prometheus.io/path: "/metrics"
    spec:
      serviceAccountName: alertmanager
      securityContext:
        runAsNonRoot: true
        runAsUser: 65534
        runAsGroup: 65534
        fsGroup: 65534
      
      containers:
      - name: alertmanager
        image: prom/alertmanager:v0.25.0
        imagePullPolicy: Always
        
        args:
        - '--config.file=/etc/alertmanager/alertmanager.yml'
        - '--storage.path=/alertmanager'
        - '--web.listen-address=:9093'
        - '--web.route-prefix=/'
        - '--cluster.listen-address=0.0.0.0:9094'
        - '--log.level=info'
        
        ports:
        - name: alertmanager
          containerPort: 9093
          protocol: TCP
        - name: mesh
          containerPort: 9094
          protocol: TCP
        
        resources:
          requests:
            memory: "256Mi"
            cpu: "100m"
          limits:
            memory: "512Mi"
            cpu: "200m"
        
        livenessProbe:
          httpGet:
            path: /-/healthy
            port: alertmanager
            scheme: HTTP
          initialDelaySeconds: 30
          periodSeconds: 30
          timeoutSeconds: 10
          failureThreshold: 3
        
        readinessProbe:
          httpGet:
            path: /-/ready
            port: alertmanager
            scheme: HTTP
          initialDelaySeconds: 10
          periodSeconds: 10
          timeoutSeconds: 5
          failureThreshold: 3
        
        securityContext:
          allowPrivilegeEscalation: false
          readOnlyRootFilesystem: true
          runAsNonRoot: true
          runAsUser: 65534
          capabilities:
            drop:
            - ALL
        
        volumeMounts:
        - name: config-volume
          mountPath: /etc/alertmanager
          readOnly: true
        - name: alertmanager-storage
          mountPath: /alertmanager
        - name: tmp
          mountPath: /tmp
      
      volumes:
      - name: config-volume
        configMap:
          name: alertmanager-config
          defaultMode: 0644
      - name: tmp
        emptyDir: {}
      - name: alertmanager-storage
        persistentVolumeClaim:
          claimName: alertmanager-storage-pvc
      
      terminationGracePeriodSeconds: 30
---
# AlertManager Service
apiVersion: v1
kind: Service
metadata:
  name: alertmanager
  namespace: leanvibe-monitoring
  labels:
    app.kubernetes.io/name: alertmanager
    app.kubernetes.io/component: alerting
  annotations:
    prometheus.io/scrape: "true"
    prometheus.io/port: "9093"
spec:
  type: ClusterIP
  ports:
  - name: alertmanager
    port: 9093
    targetPort: alertmanager
    protocol: TCP
  - name: mesh
    port: 9094
    targetPort: mesh
    protocol: TCP
  selector:
    app.kubernetes.io/name: alertmanager
    app.kubernetes.io/component: alerting
---
# AlertManager Storage PVC
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: alertmanager-storage-pvc
  namespace: leanvibe-monitoring
  labels:
    app.kubernetes.io/name: alertmanager
    app.kubernetes.io/component: storage
spec:
  accessModes:
    - ReadWriteOnce
  resources:
    requests:
      storage: 10Gi
  storageClassName: standard
---
# AlertManager ServiceAccount
apiVersion: v1
kind: ServiceAccount
metadata:
  name: alertmanager
  namespace: leanvibe-monitoring
  labels:
    app.kubernetes.io/name: alertmanager
    app.kubernetes.io/component: alerting